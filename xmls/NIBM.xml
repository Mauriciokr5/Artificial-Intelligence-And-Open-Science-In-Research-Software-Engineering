<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">New Ideas for Brain Modelling 4</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kieran</forename><surname>Greer</surname></persName>
							<email>kieran.greer@ntlworld.com</email>
						</author>
						<author>
							<persName><forename type="first">Jun</forename><surname>Pan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Billy</forename><surname>Tak</surname></persName>
							<email>billywtm@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Ming</forename><surname>Wong</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<note type="raw_affiliation">Distributed Computing Systems, Belfast, United Kingdom Office 2038, PO Box 1213, Belfast, BT1 9JY, UK.</note>
								<orgName type="department">Distributed Computing Systems</orgName>
								<address>
									<postBox>PO Box 1213</postBox>
									<postCode>2038, BT1 9JY</postCode>
									<settlement>Belfast, Belfast</settlement>
									<country>United Kingdom Office, UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<note type="raw_affiliation">Hong Kong Baptist University, Hong</note>
								<orgName type="institution">Hong Kong Baptist University</orgName>
								<address>
									<settlement>Hong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<note type="raw_affiliation">Kong Baptist University Rd, Kowloon Tong, Hong Kong</note>
								<orgName type="institution">Kong Baptist University Rd</orgName>
								<address>
									<settlement>Kowloon Tong, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<note type="raw_affiliation">Open University of Hong Kong, Hong Kong 30 Good Shepherd St, Ho Man Tin, Hong Kong.</note>
								<orgName type="institution">Open University of Hong Kong</orgName>
								<address>
									<addrLine>30 Good Shepherd St</addrLine>
									<settlement>Hong Kong, Ho Man Tin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">New Ideas for Brain Modelling 4</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C2E1B4510DAAFC6326873B0BB864E6A3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3-SNAPSHOT" ident="GROBID" when="2023-02-13T23:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>image</term>
					<term>behaviour</term>
					<term>binary-analog</term>
					<term>neural</term>
					<term>cognitive</term>
					<term>clustering interpreting</term>
					<term>linguistics</term>
					<term>e-learning</term>
					<term>natural language processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p><s>This paper continues the research that considers a new cognitive model based strongly on the human brain.</s><s>In particular, it considers the neural binding structure of an earlier paper.</s><s>It also describes some new methods in the areas of image processing and behaviour simulation.</s><s>The work is all based on earlier research by the author and the new additions are intended to fit in with the overall design.</s><s>For image processing, a grid-like structure is used with 'full linking'.</s><s>Each cell in the classifier grid stores a list of all other cells it gets associated with and this is used as the learned image that new input is compared to.</s><s>For the behaviour metric, a new prediction equation is suggested, as part of a simulation, that uses feedback and history to dynamically determine its course of action.</s><s>While the new methods are from widely different topics, both can be compared with the binary-analog type of interface that is the main focus of the paper.</s><s>It is suggested that the simplest of linking between a tree and ensemble can explain neural binding and variable signal strengths.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p><s>This paper continues the research that considers a new cognitive model based strongly on the human brain, last updated in <ref type="bibr" target="#b0">Greer (2016)</ref>.</s><s>In particular, it considers figure 4 of that paper (Figure <ref type="figure">below</ref>) and how it might be useful in practice.</s><s>The paper also describes some new methods in the areas of image processing and behaviour simulation.</s><s>The image processing introduces a most classical form of pattern cross-referencing, while the behaviour equations used feedback for a memory-type of cross-referencing.</s><s>The work is all based on earlier research by the author and the new additions are intended to fit in with the overall design.</s><s>For image processing, a grid-like structure is used with 'full linking', if you like.</s><s>Each cell in the classifier grid stores a list of all other cells it gets associated with and this is used as the learned image that new input is compared with.</s><s>For the behaviour metric, a new prediction equation is suggested, as part of a simulation, that uses feedback and history to dynamically determine its current state and course of action.</s><s>While the new methods are from widely different topics, both can be compared with the binary-analog type of interface that is the main focus of the paper.</s><s>Sensory input may be static and binary, but crossreferences result in variable comparisons that make the input more dynamic.</s><s>It is suggested that the simplest of linking between a tree and ensemble can explain neural binding and variable signal strengths.</s></p><p><s>The rest of the paper is organised as follows: section 0 introduces an image processing method that cross-references at a pixel level to associate images.</s><s>Section 0 describes some related work.</s><s>Section 0 re-visits the behaviour metric of an earlier paper and updates that with a new predictive equation.</s><s>This feeds earlier evaluations back into the equation, to allow it to self-adjust.</s><s>Section 0 describes concept aggregation or binding, for realising global concepts, while section 0 considers a process for neural binding that could relate to consciousness.</s><s>Finally, section 0 gives some conclusions to the work.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Image Processing</head><p><s>This section describes a very basic image recognition algorithm, but one that has characteristics of the other algorithms developed as part of the work, see the related work section.</s><s>For this paper, images are represented by a 2-D grid, with a black cell meaning that a pixel is present and a white cell meaning that it is empty.</s><s>A classifier can use the same grid-like structure, where all of the cells can link to each other.</s><s>The author has used this structure before in <ref type="bibr" target="#b0">Greer (2016)</ref> and it is a type of entropy classifier.</s><s>It attempts to reduce the error overall and is not so concerned with minimising individual associations.</s><s>The paper <ref type="bibr" target="#b1">Greer (2017)</ref> describes a classifier that is conjecturally more visual in nature than other types and it also uses a complete linking method.</s><s>Instead of several levels of feature refactoring, it is a 1-level impression only.</s><s>With the image classifier, each cell stores a count of every other cell it gets associated with, when averaging this can determine what cells are most similar to the pixel in question.</s><s>Figure is an example of the clustering technique.</s><s>If the top LHS grid is the first image to be mapped, then for cell A1, the other black cells are recorded as shown, with a count of 1.</s><s>The count would then be incremented each time a cell is recorded again, for example, after the second image, cell A3 would lose a count.</s><s>The idea of linking everything this way has now been used 3 times.</s><s>Using this algorithm, a set of hand-written numbers (Chars74K, 2017) was selected as the test data.</s><s>There were 9 numbers in total and 55 examples of each number.</s><s>Each number was trained on a separate classifier, where each cell would store the other related cell associations.</s><s>The counts could then be averaged to produce the weight values.</s><s>To use the system, a new binary image would be presented to each of the trained classifiers and it would be assigned to the classifier that matched closest.</s><s>It is easy to recognise pixels in the input image, but the problem is sorting any other pixels that they are associated with.</s><s>For each pixel in the input image therefore, the weighted value of the related classifier cell can be retrieved.</s><s>This would also have links to other cells, maybe not in the input image.</s><s>For example, if the counts are as shown and a new image is presented that contains pixels in cells A1 and A2 -then the classifier would return cells A1, A2 plus B1 and C1.</s><s>A3 might not be returned depending on a set threshold value.</s><s>The success score is then the percentage of retrieved weighted cells in the classifier that are also in the input image, compared to the number that are not in the image.</s><s>For this example, 2 cells are in the input image while 2 cells are not, leading to a success score of 1.</s><s>The weight value of the cell can be considered as an association strength and the idea may be auto-associative.</s></p><p><s>After training on the hand-written numbers, the same dataset was fed through the classifiers again for recognition only.</s><s>The test results are not particularly good and to improve it, some level of scaling would be required.</s><s>There is a problem of a larger image covering a smaller one with the currently tried dataset.</s><s>An average success score of only 46% was achieved with this basic version, with a best score for a number of 89% and a worst score of 15%; although state-of-the-art is only about 55%.</s><s>It was interesting that the classifier would try to return a picture that was more a reflection of itself.</s><s>So regardless of what the input was, for example, the number 1 classifier would try to return an image that looked like a '1'.</s><s>If the input image was a '4' however, then maybe the number 4 classifier would return a more accurate comparison and therefore win the matching competition.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related Work</head><p><s>The author's own papers that are quoted <ref type="bibr" target="#b6">(Greer, 2011</ref><ref type="bibr" target="#b1">(Greer, -2017) )</ref> are all relevant to the research of this paper.</s><s>The image processing of section 0 has already been tried in de Campos, <ref type="bibr" target="#b14">Babu and Varma (2009)</ref>, where they tested the full dataset.</s><s>Their results were better overall, with maybe 55% accuracy and over a larger dataset.</s><s>As stated however, the tests here are only initial results and it would be expected that some improvement would be possible, especially if the images can be scaled.</s><s>The recently found paper <ref type="bibr" target="#b15">Kowalski (1972)</ref> looks significant and the general architecture <ref type="bibr">(Greer, 2016, figure</ref>  <ref type="figure" target="#fig_1">2</ref>, for example)) could have analogies with bi-directional searches in the and-or with theorem-proving graphs architecture of that paper.</s><s>As suggested, and-or could work from goals to axioms (the neural network in the general model and theorem-proving from axioms to goals (the concept trees in the general model).</s><s>The paper Sukanya and Gayathri (2013) models at a higher behaviour level, but it is interesting that the behaviours are considered to be unique (time or sequence-based) sets of events and these event patterns are then clustered, rather than each individual event.</s><s>The idea of using unique sets of nodes to cluster with has also been used for the symbolic neural network <ref type="bibr" target="#b6">(Greer, 2011</ref>).</s></p><p><s>An earlier paper on control theory <ref type="bibr" target="#b7">(Yashchin, 1987)</ref> posts some interesting equations that are similar to ones in this paper.</s><s>Equation 1 there, for example, looks like the image success score ratio and equation 7 is a likelihood ratio test that is also trying to maximise inside some type of sequence.</s><s>The behaviour metric of section 0 has only been updated with a new predictive equation, where the first paper <ref type="bibr">(Greer, 2013)</ref> notes some references, including <ref type="bibr" target="#b8">Bryant and Miikkulainen, (2007)</ref>; <ref type="bibr" target="#b9">Hanks, Pollack and Cohen, (1993)</ref>; <ref type="bibr" target="#b10">Macal and North, (2010)</ref> and <ref type="bibr" target="#b11">Pollack and Ringuette, (1990)</ref>.</s><s>One interesting aspect of the equation is that it uses a feedback mechanism which appears to be similar to one that was part of another research project and even in the project code<ref type="foot" target="#foot_0">4</ref> .</s><s><ref type="bibr" target="#b12">Hawkins and Blakeslee, (2004)</ref> describe how a region of the cortex might work (p.</s><s>57) and they note an input signal being voted on by a higher level, where one higher level pattern set will win and switch off the other sets.</s><s>They also state explicitly that the higher level is voting to 'fit' its label better than the other patterns.</s><s>It may be trying to return its own image as the input signal and the best match there with the input signal should win.</s><s>The theory that they state is that a region learns when it may be important and then it can become partially active, as part of a memory or prediction.</s><s>So, this is a type of reasoning, to play over previous scenarios, even when they have not happened in the current situation yet.</s><s>That can then maybe be reinforced further by specific instance values, making it the real decision.</s><s>The following quote is also interesting: 'Every moment in your waking life, each region of your neocortex is comparing a set of expected columns driven from above with the set of observed columns driven from below.</s><s>Where the two sets intersect is what we perceive.</s><s>If we had perfect input from below and perfect predictions, then the set of perceived columns would always be contained in the set of predicted columns.</s><s>We often don't have such agreement.</s><s>The method of combining partial prediction with partial input resolves ambiguous input, it fills in missing pieces of information, and it decides between alternative views.'</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Cognitive Modelling</head><p><s>The paper <ref type="bibr">(Senkowski et.al., 2008)</ref> introduces the idea of temporal synchrony and synchronised oscillatory activity as important for multisensory perception.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Neural Binding</head><p><s>There is quite a lot of research and philosophy into the idea of neural binding.</s><s>At its most basic, it means 'how do neural ensembles that fire together be understood to represent the said concept'.</s><s>For example, questions like 'why don't we confuse a red circle and a blue square with a blue circle and a red square' <ref type="bibr" target="#b18">(Feldman, 2013)</ref> need to be answered.</s><s>It includes the idea of consciousness and how the brain is able to be coherent, but while there are lots of theories, there are not a lot of very specific results for the binding mechanism itself.</s><s>Some cognitive models for the real brain include temporal logic or predicate calculus rules <ref type="bibr" target="#b18">(Feldman, 2013)</ref> to explain how variables can bind with each other and reasoning can be obtained.</s><s>This includes the flow of information in both directions and so the basic circuits of this and earlier papers would not be too extravagant.</s><s>The paper <ref type="bibr" target="#b19">Mashour (2004)</ref> is a philosophical paper about how the neural binding mechanism may work.</s><s>It argues for quantum mechanics, to allow neurons to be represented in more than 1 pattern simultaneously and probably the resulting merging of the patterns into a consciousness.</s><s>The author would only favour quantum mechanics as a last resort and in section 0, a relatively simple method for representing the same neuron in different patterns is suggested.</s><s>If time differences between the patterns is very small, then they could still merge into a single coherent message.</s><s>This could be especially true for the argument against Hebbian cell assemblies.</s><s>The paper <ref type="bibr" target="#b20">Cer and O'Reilly (2006)</ref> describes a theory that is quite similar.</s><s>They call the framework the Specialized Neural Regions for Global Efficiency (SNRGE) framework.</s><s>The paper describes that 'the specializations associated with different brain areas represent computational trade-offs that are inherent in the neurobiological implementation of cognitive processes.</s><s>That is, the trade-offs are a direct consequence of what computational processes can be easily implemented in the underlying biology.'</s><s>The specializations of the paper correspond anatomically to the hippocampus (HC), the prefrontal cortex (PFC), and all of neocortex that is posterior to prefrontal cortex (posterior cortex, PC).</s><s>Essentially, prefrontal cortex and the hippocampus appear to serve as memory areas that dynamically and interactively support the computation that is being performed by posterior brain areas.</s><s>The PC stores overlapping distributed representations used to encode semantic and perceptual information.</s><s>The HC stores sparse, pattern separated representations used to rapidly encode ('bind') entire patterns of information across cortex while minimizing interference.</s><s>The FC stores isolated stripes (columns) of neurons capable of sustained firing (i.e., active maintenance or working memory).</s><s>They argue against temporal synchrony, because of the 'red circle blue square' question and prefer to argue for coarse-coded distributed representations (CCDR) <ref type="bibr" target="#b21">(Hinton, McClelland and Rumelhart, 1986</ref> and others) instead.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Cognitive Behaviour</head><p><s>An earlier paper introduced a set of equations that were based on the collective behaviour research of <ref type="bibr" target="#b22">Garnier, Gautrais and Theraulaz (2007)</ref>.</s><s>They proposed a set of characteristics for modelling the stigmergic behaviour of very simple animals, such as ants.</s><s>They proposed to use coordination, cooperation, deliberation and collaboration, as follows:</s></p><p><s> Coordination -is the appropriate organisation in space and time of the tasks required to solve a specific problem.</s><s> Cooperation -occurs when individuals achieve together a task that could not be done by a single one.</s><s> Deliberation -refers to mechanisms that occur when a colony faces several opportunities.</s></p><p><s>These mechanisms result in a collective choice for at least one of the opportunities.</s><s> Collaboration -means that different activities are performed simultaneously by groups of specialised individuals.</s><s>They note that these are not mutually exclusive, but rather contribute together to accomplish the various collective tasks of the colony.</s><s>This led to a set of equations by the author <ref type="bibr">(Greer, 2013)</ref> for modelling these types of entity.</s><s>The model is actually behaviour-based not entity-based, where the entity instances are then made up of a set of the pre-defined behaviours, with the following characteristics:</s></p><p><s>1. Individual agent characteristics: Relate to an agent as an individual:</s></p><p><s>1.1.</s><s>Ability: this defines how well the behaviour is able to execute the required action.</s><s>1.2.</s><s>Flexibility: this defines how well an agent performing a behaviour can adapt or change to a different behaviour if the situation requires it to.</s><s>This can be seen as the ability to make that decision individually.</s><s>The collective capabilities described next can then be seen as the ability to be flexible after an environment response.</s><s>2. Collaborative agent characteristics: These relate to the agent working in a team environment:</s></p><p><s>2.1.</s><s>Coordination: this defines how well the agent can coordinate its actions with those of other agents.</s><s>This is again a behaviour selection, related to flexibility, but this variable measures the group aspect of the attribute after interaction with other agents.</s><s>2.2.</s><s>Cooperation: this defines how well an agent performing an action can cooperate with other agents also involved in that action.</s><s>How well can the selected behaviours work together?</s><s>2.3.</s><s>Communication: this defines how well the agents can communicate with each other.</s><s>This is defined as an input signal and an output signal for each behaviour type.</s><s>Behaviours could require local or remote communication, for example.</s></p><p><s>The metric is quite well balanced, with approximately half of the evaluation going to the individual capabilities and half going to the group capabilities.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Problem Modelling</head><p><s>It is possible to specify a problem with all of the related agents and actions that are part of the solution space.</s><s>The modelling is based around the behaviour types that are used to solve the problem, where the same type definitions can be used, both to model the problem and also to simulate its execution.</s><s>The agents are defined by agent types, where an agent type can perform a particular set of behaviours.</s><s>So, if the same behaviour type is to be performed at different levels of success; for static values, this would require different behaviour definitions, or for dynamic ones the value can change through an equation.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Behaviour Equations</head><p><s>The problem is therefore modelled as sets of agents that can each perform a set of behaviours.</s><s>The Problem Success Likelihood (PSL) is the summed result of the behaviour scores and estimates how well the problem can be solved.</s><s>The top part of the PSL value, shown in equation 1, evaluates the average agent complexity (EC s ), as just described.</s><s>When modelling, this is measured for all of the behaviour type instances (B s ) that are part of the problem behaviour set (PBS).</s><s>This can be no larger than the optimal problem complexity (PC) value of 1.0.</s><s>The problem complexity is a factor of how intelligent the agents need to be to solve it.</s><s>Because the evaluations are all normalised, in a static specification, the maximum value that the problem complexity can be is 1.0.</s><s>If all behaviours are perfect, they will also only sum to 1 as well.</s><s>The problem success likelihood, can therefore be defined as follows: PSL =</s></p><p><s>(1)</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Individual Parameters</head><p><s>The individual capabilities of a behaviour can be modelled as follows:</s></p><formula xml:id="formula_0">EC s = (2) I s =<label>(3)</label></formula><p><s>The agent or entity complexity (EC s ) for behaviour s is a factor of its ability to perform the related behaviour attributes of intelligence and collective capabilities.</s><s>The agent intelligence (I s ) is a factor of its ability (BA s ) and flexibility (BF s ) capabilities for the specified behaviour.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Team Work</head><p><s>The collective or team work capabilities (COL s ) of a behaviour are modelled as follows:</s></p><formula xml:id="formula_1">COL s = (4) COM s = (5)</formula><p><s>The collective capabilities of the agent performing the behaviour are its ability to cooperate with other agents (COP s ), coordinate its actions with them (COR s ) and also communicate this (COM s ), normalised.</s><s>The communication capabilities of the agent for the behaviour s include its ability to send a signal to another agent (SO s ) and also its ability to receive a signal from another agent (SI s ).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Prediction Operation for the Metric</head><p><s>When simulating the problem, the Problem Complexity value can change.</s><s>The success likelihood then becomes an individual evaluation, based on its knowledge and understanding of the environment.</s><s>This can be defined by the subset of behaviours the agent has either performed or has interacted with from other agents.</s><s>For a more intelligent agent, the memory or history of earlier events can lead to a prediction operation that can reason over the earlier events.</s><s>It could be a deliberation function that is fed the history of earlier and/or possible choices, before selecting the most appropriate one.</s></p><p><s>For example, Equation 3 of section 0 defines agent intelligence as a combination of ability and flexibility.</s><s>The idea is the ability to perform the intended behaviour but also flexibility to change or adapt the individual behaviour depending on some response.</s><s>Ideally, an agent would score high in both and a modelling scenario that uses static values would be able to demonstrate this.</s><s>If instead, running the agents in a simulation, it may be more interesting to let them change their behaviours dynamically, but again constrained by the pre-defined environment.</s><s>This leads to the idea of a prediction metric that is influenced by what the agent can do and also what it did in the past.</s><s>The current situation is the most important and so the decision there has the largest weight.</s><s>The prediction could then include decreasing values for earlier related events.</s><s>These can be factored as a count of earlier events times a factor for the time when they occurred.</s><s>If the behaviour was not repeated, then maybe something went wrong, such as an unfavourable response.</s><s>These responses, including for the current situation, would change the state of the agent into what it then has to deal with.</s><s>The equation would be something like: <ref type="bibr">(6)</ref> where: EC s1 is the currently selected individual behaviour complexity, EC m is any previously selected individual behaviour complexity, for any related scenario, n is number of times in memory that the previous event occurred, R is the response or impact of the event, t is the last time the event occurred, M is the total number of behaviour-response pairs stored in memory, f is some function evaluation over the variable set, maybe 'n(EC + R) / t' if R is a specific response, or a multiplication if it is the weight of the response.</s></p><p><s>When the agent selects a new behaviour, it is expecting a positive response.</s><s>After a reply from the environment, the individual behaviour plus the response is fed back into the equation to get a new amount.</s><s>If this is less than expected -'current Pr plus new EC', then the response has been a negative one and possibly a different behaviour should be selected.</s><s>This type of process can repeat, with bad responses being flagged and not selected again, for example, until a decision is made, maybe a new stable state is reached.</s><s>As the equation calculates, it also feeds back its current state to update its evaluation for the next selection.</s><s>The responses are therefore even more responsible for changing the agent state, where the behaviour selection, using the entity complexity, is an individual one, maybe based more on knowledge.</s><s>So again, there is a hint of a simpler evaluation, which is the knowledge-based decision, balancing itself with the more complex decision, after the response is also factored in.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Self-Adjusting Evaluation</head><p><s>A more intelligent version of the metric for a simulation might therefore look as follows:</s></p><p><s>(7)</s></p><p><s>Where the predictive equation can replace the entity complexity and both of the flexibility parts.</s><s>The prediction is modelled as in equation 6, by the agent decision plus its reaction to any response.</s><s>A dynamic problem complexity can be measured as in equation 8 and is essentially the fraction of all behaviours that the agent knows about.</s><s>Depending on how this is measured, a multiplication might be more appropriate for the PSL.</s><s>However, if I only 'know' about 1 behaviour, for example, then based on my own knowledge, I can solve that more easily than if I have to deal with several known behaviours.</s></p><p><s>(8)</s></p><p><s>The collective capabilities are thus reduced to cooperation and communication with other entities, where coordination is moved to the predictive part.</s></p><p><s>(8)</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Testing</head><p><s>The behaviour metric was tested in <ref type="bibr">Greer (2013)</ref>.</s><s>There has not been an opportunity to test the new predictive equation or its feedback algorithm and so this paper presents the theory of it only and notes the relation of the theory to the other research.</s><s>However, a worked example described next, should help to show how it would work in practice.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Worked Behaviour Example</head><p><s>Consider the following scenario: an agent finds itself in a situation S 1 .</s><s>The agent is modelled with behaviours B 1 to B 5 and the world is modelled with behaviours B 1 to B 10 .</s><s>The agent has encountered the same scenario S 1 before and attempted the following behaviour set with related events, to deal with it: Event B 3 was tried at time t 3 and resulted in a response R 8 .</s><s>Event B 4 was tried at time t 2 and resulted in response R 6 .</s></p><p><s>Based on this, behaviour B 4 is selected again, leading to the equation:</s></p><formula xml:id="formula_2">Pr = B 4s1 + (1 x (B 4 + R 6 ) / 2) + (1 x (B 3 + R 8 ) / 3)</formula><p><s>The scene is an interactive one, with another agent able to reply.</s><s>The other agent also knows the scenario and replies with a behaviour B10.</s><s>This is found to be unfavourable for the agent and reduces its overall evaluation through the equation:</s></p><formula xml:id="formula_3">Pr = (B 4S1 + R 10S1 ) + (1 x (B 4 + R 6 ) / t 2 ) + (1 x (B 3 + R 8 ) / t 3 ), where R 10S1 is negative.</formula><p><s>Therefore, the prediction reduces and the agent is required to try again.</s><s>It now has knowledge of the reply B10 and also knows not to use behaviour B4 if it doesn't have to.</s><s>Therefore, a new response based on its new history could lead to:</s></p><formula xml:id="formula_4">Pr = B 2S1 + (1 x (B 4S1 + R 10S1 ) / t 2 ) + (1 x (B 4 + R 6 ) / t 3 ) + (1 x (B 3 + R 8 ) / t 4 )</formula><p><s>The reply by the environment, B 10 again, is not as unfavourable now and so the prediction increases.</s><s>Based on other criteria, the behaviour can be played again, or a satisfactory situation may have been achieved.</s><s>In either case, to resolve this situation, two behaviours were tried and both were fed back into the evaluation function.</s><s>The first one even counted as part of the history for selecting the second one.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Concept Binding</head><p><s>Concept aggregation or binding is mentioned as part of the symbolic neural network <ref type="bibr" target="#b6">(Greer, 2011)</ref>.</s><s>This is an experience-based structure that combines lower-level concepts into more complex global ones and would work in the more intelligent brain region.</s><s>Other related papers <ref type="bibr" target="#b1">(Greer, 2017;</ref><ref type="bibr" target="#b0">2016)</ref> have developed algorithms that link everything together and then sort using entropy.</s><s>The image-processing model of section 0, for example, introduces the variable structure through cross-referencing.</s><s>The behaviour metric of section 0 does not fit quite as obviously.</s><s>The sensory input must still come first from the environment, before deciding on a plan.</s><s>The behaviour selection and reasoning process must therefore occur afterwards, using the higher-level brain regions to sort the lower-level ones.</s><s>But a binding is simply a repeat of the pattern and it does not have to represent anything other than what the ensemble mass represents.</s><s>So it can be used in exactly the same context.</s><s>With one visual system theory <ref type="bibr">(Singer and Gray, 1995 and others)</ref>, synchronous oscillations in neuronal ensembles bind neurons representing different features of an object.</s><s>Gestalt psychology is also used, where objects are seen independently of their separate pieces.</s><s>They have an 'other' interpretation of the sub-features and not just a summed whole of them.</s><s>Although, there are still problems with the theories, including the requirement for too many independent neural constellations to represent every feature.</s></p><p><s>The numerical problem can therefore be helped with some level of cross-referencing.</s><s>The question like 'why don't we confuse a red circle and a blue square with a blue circle and a red square' <ref type="bibr" target="#b18">(Feldman, 2013</ref>) could be answered if 'red', 'blue', 'circle' or 'square' are individual concepts that also cross-reference each other.</s><s>Individual means a base node in a tree and crossreference means a leaf node in another tree.</s><s>If a tree is accepted as part of a circuit, then the base neuron will receive positive feedback, which may be recognised more because of the greater firing effort.</s><s>Leaf nodes would also have to be relevant to complete a circuit, but they may also be peripheral to a main concept and so can act more as links.</s><s>One leaf node would also be the base of another tree, when both trees could be active at the same time and relate to the same larger concept.</s><s>This is illustrated in Figure .</s><s>The concepts of red, blue, circle and square are all base concepts learned by the system and also have cross-referenced branches in other trees.</s><s>Some neurons can have 1000 branches or more 5 .</s><s>If the senses send signals about red and circle, for example, then the two central trees can complete a circuit, even if the concepts exist in other places as well.</s><s>For reasoning then, there would also be influences from the higher-level processes that perform other types of aggregation, or for synchronisation.</s><s>It is therefore possible to give concepts graded strengths and also any arbitrary mix of the learned base set.</s><s>This is already part of the concept trees research <ref type="bibr" target="#b3">(Greer, 2014)</ref>, where a leaf node in one tree links to a base node in another tree.</s><s>Or to put it another way, if a base node branches to link with another tree, it represents the same thing in any other tree.</s><s>The concept tree may be too semantic for the level being considered here and their base concepts would not be 'anchored' because there is an idea that concept trees can re-join with each other.</s><s>So possibly, the path description for Figure is only 1 or 2 levels deep -the base node and its same branches.</s><s>The related Concept Base <ref type="bibr" target="#b6">(Greer, 2011)</ref> however has been used to manage flat hierarchies in that paper, or the trees in other papers, where the flat hierarchy has been associated with a cognitive process.</s></p><p><s>6. Neural Binding for a Binary-Analog Interface While section 0 looked at the coarser concept binding, this section considers again the idea of neuron binding<ref type="foot" target="#foot_2">6</ref> .</s><s>Biology has already suggested theories about neural oscillations and binding that include neural pairing.</s><s>The pairing helps to group the neurons into specific patterns that the brain can understand, when different features can become synchronised and oscillate together.</s><s>The binding theory of this paper is described in Figure .</s><s>In the figure, a neuron in a base ensemble mass binds with a neuron in a related hierarchical structure.</s><s>The hierarchy gives more meaning to the structure and helps to guide a search process, but it is not clear how or why this structure would form.</s><s>Signal strength would be an attractive option to produce the hierarchical neuron, but if the base node has the strongest signal, then that should result in a longer link to its paired neuron.</s><s>The construction of the hierarchy is therefore more likely to be based on time.</s><s>When neurons fire they create new neurons and a neuron must exist before it can form a link to another one.</s><s>The neurons that form first are therefore more likely to link to other neurons that form later and so in a mechanical sense, the hierarchy could be created.</s></p><p><s>It is also useful to consider electrical synapses, which can be bi-directional and setup an oscillating wave between close neural regions.</s><s>They are created along with chemical synapses.</s><s>The point of the pairing is this resonance and so a weaker electrical signal would be ideal.</s><s>Quantum mechanics is one theory used to exaplin how the conscious might work, where several patterns and states can collapse into one.</s><s>With a paired neuron however, there can be resonance between the pair without a quantum element.</s><s>This resonance could produce a signal, similar to how different sized pipes produce a note.</s><s>The resonance is obviously very quick and so it would all meld into the one signal.</s><s>If the base ensemble can refresh the whole pattern as well, then that variable process can (re)activate parts of the structure and in a timed way.</s><s>This model fits deeper in the brain however and is not intended for the intelligent cortex area.</s></p><p><s>The model is also based on the idea of an auto-associative neural network.</s><s>The Hopfield neural network <ref type="bibr" target="#b23">(Hopfield, 1982)</ref>, and its stochastic equivalents are auto-associative or memory networks.</s><s>With the memory networks, information is sent between the input and the output until a stable state is reached, when the information does not then change.</s><s>These are resonance networks, such as bidirectional associative memory (BAM), or others <ref type="bibr" target="#b24">(Rojas, 1996)</ref>, but they can only provide a memory recall -they map the input pattern directly to the output pattern.</s><s>If some of the input pattern is missing however, they can still provide an accurate recall of the whole pattern.</s><s>They also prefer the data vectors to be orthogonal without overlap.</s><s>This is however ideal for the binding that only wants to reproduce the base ensemble in the hierarchy.</s><s>Image Processing Example An an example, the image-processing algorithm of section 0 is mapped to the neuron pairing architecture in this section.</s><s>This is not final and there are questions about how exactly it might work, but there is also a clear process that can relate the two.</s><s>The first thing to consider is the neuron ensemble and while neurons are continually being created, the ensemble mass is assumed to exist already.</s><s>When some of it is excited, this then starts the binding process with the neurons in the hierarchy.</s><s>The process is shown in Figure .</s><s>The LHS represents the lower ensemble mass, where an input has activated the central column of black neurons.</s><s>With the image-processing algorithm, each pixel (neuron) on the RHS image relates to the same pixel (neuron) on the LHS image.</s><s>The grey squares represent additional pixels (neurons) that have been associated during the reinforcement procedure.</s><s>The binding process can probably include more than 1 base beuron and hierarchy at a time and it is probably not the case that only the grey squares would be further up a hierarchy.</s><s>While that part is not clear, what is good about the binding is that it should introduce more accuracy into the recognition result.</s><s>It would require for both the input sensory image and the stored hierarchy image to both fire the same related set of neurons, for the oscillations to register a persistent signal between them.</s><s>If there is a neuron in the hierarchy that sends a signal back to the sensory input and it is not part of the pattern, then it cannot oscillate, so that part of the error can be removed.</s><s>If part of the sensory input is missing from the hierarchy, then it cannot oscillate and so that part of the input needs to be learned.</s><s>A third possibility is if the hierarchy returns a signal not in the sensory input, but that has links in the ensemble mass.</s><s>It may usually be part of the input pattern and so through the links it can get activated as part of the pattern.</s><s>A fourth possibility is if a lot of the hierarchy sends back signals to inactive neurons, but the hierarchy should be more accurate and is activated from the ensemble.</s><s>It is also controlled from further levels above, so this possibility is not as likely.</s><s>RHS relates to hierarchy, with a direct mapping.</s><s>The two red lines show where the ensemble is missing and so it needs to be learned.</s><s>The blue lines show extra neurons from the hierarchy back to the ensemble, but can be removed as error.</s></p><p><s>The other paired black squares represent where the patterns match and can oscillate together.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p><s>This paper has mostly considered a binding problem and the implications of a binary-analog conversion process.</s><s>This has led to some interesting results, both in the areas of image processing and higher-level reasoning.</s><s>It has also helped when thinking about the temporal synchrony problems of neural binding and how separate parts can be re-combined into a more coherent whole.</s><s>The binding can also help with recognition accuracy.</s><s>The behaviour metric has been updated to include a predictive part that may be used as part of a simulation.</s><s>This allows the metric to be more intelligent and should help to clarify the flexibility attributes that it has.</s><s>A behaviour decision is based on the agent's current state, its abilities and also its memory.</s></p><p><s>If the model of this and earlier papers is used, then (sub)concepts can in fact be represented individually, with lots of cross-linking representing the different contexts.</s><s>With so many neurons in the brain, depending on how a scenario is broken down, why could it not accommodate this?</s><s>For the pattern ensembles, base nodes that link as branches in other trees can simply represent themselves.</s><s>This is a simplification of concept trees, where symbolically or conceptually, the node representation is only 1 or 2 levels deep.</s><s>If there is a tree structure however, then there can be deeper paths that can relate to graded signal strengths, or even allow for different connection patterns over the same ensemble.</s><s>Also key is reinforcement from above, through reasoning, that completes the circuits.</s><s>It can still be shown that the ideas fit together into a common model, even if it uses a lot of standard and compatible structures.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p><s>Political interpreting serves as a significant means for foreign language speakers to access a government's official policies <ref type="bibr">(Gagnon, 2010;</ref><ref type="bibr">Schäffner &amp; Bassnett, 2010)</ref>.</s><s>Interpreters of senior government officials therefore often face great challenges and work under extreme stress, as any misinterpretation or misuse of interpreting strategy can lead to regional and even international disputes.</s><s>Apart from excellent language abilities and a broad knowledge base, interpreters working in political settings need to be sensitive to the pragmatics of political discourse, including but not limited to "understatement, unspoken assumptions or subtle emphases, innuendo and hedging, or things left unsaid", and render them appropriately in the target language <ref type="bibr">(Buri, 2015, para.17)</ref>.</s><s>It is therefore important to study the pragmatic strategies applied by interpreters in political settings, especially when they render propositions that may sound unfavorable or contrastive to people's presuppositions.</s><s>In this regard, the use of contrastive markers -a major type of pragmatic markers -serves as a key linguistic indicator of the application of such strategies.</s><s>Nevertheless, not much has been explored in this aspect.</s></p><p><s>In addition, Chinese is often regarded as a language that is typically implicit and pragmatically significantly different from English, which can be evidenced by its politeness maxims of <ref type="bibr">self-denigration, address-term, refinement, agreement and virtue (Gu, 1992)</ref>.</s><s>An examination of the use of contrastive markers that signal non-agreement in this language and their renditions in</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc><div><p><s>Figure 1.</s><s>Example mapping of cells presented as an image.</s></p></div></figDesc><graphic coords="2,171.36,239.28,287.88,152.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc><div><p><s>Figure 2. One level of linking in a temporal model defines a particular ensemble mix.</s></p></div></figDesc><graphic coords="9,137.64,101.16,355.20,127.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc><div><p><s>Figure 3. Neuron Pairing: an ensemble neuron links with a hierarchal neuron.</s><s>Also figure 4 in<ref type="bibr" target="#b0">Greer (2016)</ref></s></p></div></figDesc><graphic coords="10,216.72,197.88,161.64,227.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc><div><p><s>Figure 4. LHS relates to neuron binding ensemble mass, with central column activated.</s></p></div></figDesc><graphic coords="11,153.60,87.48,288.00,171.72" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0">Cognitive Algorithm by Boris Kazachenko, http://www.cognitivealgorithm.info/.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1">Prof K. Arai, SAI'14.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2">See Wikipedia, for example.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p><s>I would like to thank the reviewer for some useful comments about the paper structure and content.</s></p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Greer</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1612.00369" />
		<title level="m">New Ideas for Brain Modelling 3</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Greer, K., (2016), New Ideas for Brain Modelling 3, available on arXiv at https://arxiv.org/abs/1612.00369.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A single-pass classifier for categorical data</title>
		<author>
			<persName><forename type="first">Kieran</forename><surname>Greer</surname></persName>
		</author>
		<idno type="DOI">10.1504/ijcsyse.2017.083139</idno>
		<ptr target="http://arxiv.org/abs/1503.02521" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Computational Systems Engineering</title>
		<title level="j" type="abbrev">IJCSYSE</title>
		<idno type="ISSN">2046-3391</idno>
		<idno type="ISSNe">2046-3405</idno>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1/2</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2017">2017</date>
			<publisher>Inderscience Publishers</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Greer, K., (2017), A Single-Pass Classifier for Categorical Data, Special Issue on: IJCSysE Recent Advances in Evolutionary and Natural Computing Practice and Applications, Int. J. Computational Systems Engineering, Inderscience, Vol. 3, Nos. 1/2, pp. 27 -34. Also available on arXiv at http://arxiv.org/abs/1503.02521.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">When is a stroke not a stroke? An unusual mimic presenting to AMU</title>
		<author>
			<persName><forename type="first">Shyamal</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Smallwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyacinth-John</forename><surname>Abu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youssif</forename><surname>Abousleiman</surname></persName>
		</author>
		<idno type="DOI">10.52964/amja.0599</idno>
		<ptr target="http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/" />
	</analytic>
	<monogr>
		<title level="j">Acute Medicine Journal</title>
		<title level="j" type="abbrev">Acute Med</title>
		<idno type="ISSN">1747-4884</idno>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="36" />
			<date type="published" when="2016-01-01" />
			<publisher>Rila Publications Ltd</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">The Chars74K dataset, http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/. (last accessed 15/8/17).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Concept Trees: Building Dynamic Concepts from Semi-structured Data Using Nature-Inspired Methods</title>
		<author>
			<persName><forename type="first">Kieran</forename><surname>Greer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-12883-2_8</idno>
		<ptr target="http://arxiv.org/abs/1403.3515" />
	</analytic>
	<monogr>
		<title level="m">Complex System Modelling and Control Through Intelligent Soft Computations</title>
				<editor>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Azar</surname></persName>
		</editor>
		<meeting><address><addrLine>Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014-11-30">2014. 2014</date>
			<biblScope unit="volume">319</biblScope>
			<biblScope unit="page" from="221" to="252" />
		</imprint>
	</monogr>
	<note>Studies in Fuzziness and Soft Computing. Published on</note>
	<note type="raw_reference">Greer, K. (2014). Concept Trees: Building Dynamic Concepts from Semi-Structured Data using Nature-Inspired Methods, in: Q. Zhu, A.T Azar (eds.), Complex system modelling and control through intelligent soft computations, Studies in Fuzziness and Soft Computing, Springer-Verlag, Germany, Vol. 319, pp. 221 -252, 2014. Published on arVix at http://arxiv.org/abs/1403.3515.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Metric for Modelling and Measuring Complex Behavioural Systems</title>
		<author>
			<persName><forename type="first">Kieran</forename><surname>Greer</surname></persName>
		</author>
		<idno type="DOI">10.9790/3021-031151928</idno>
		<idno>ISSN: 2278-8719</idno>
		<ptr target="http://arxiv.org/abs/1403.0770" />
	</analytic>
	<monogr>
		<title level="j">IOSR Journal of Engineering</title>
		<title level="j" type="abbrev">IOSRJEN</title>
		<idno type="ISSN">2278-8719</idno>
		<idno type="ISSNe">2250-3021</idno>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="19" to="28" />
			<date type="published" when="2013-11">2013. November</date>
			<publisher>IOSR Journals</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Greer, K. (2013). A Metric for Modelling and Measuring Complex Behavioural Systems, IOSR Journal of Engineering (IOSRJEN), Vol. 3, Issue 11, November, pp. 19 -28, e-ISSN: 2250- 3021, p-ISSN: 2278-8719. Published on arXiv at http://arxiv.org/abs/1403.0770.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Turing: Then, Now and Still Key</title>
		<author>
			<persName><forename type="first">Kieran</forename><surname>Greer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-29694-9_3</idno>
		<ptr target="http://arxiv.org/abs/1403.2541" />
	</analytic>
	<monogr>
		<title level="m">Studies in Computational Intelligence</title>
				<editor>
			<persName><forename type="first">X-S</forename><surname>Yang</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Berlin Heidelberg</publisher>
			<date type="published" when="2012">2012. 2012. 2013. 2013</date>
			<biblScope unit="volume">427</biblScope>
			<biblScope unit="page" from="43" to="62" />
		</imprint>
	</monogr>
	<note>Published on</note>
	<note type="raw_reference">Greer, K. (2012). Turing: Then, Now and Still Key, in: X-S. Yang (eds.), Artificial Intelligence, Evolutionary Computation and Metaheuristics (AIECM) -Turing 2012, Studies in Computational Intelligence, 2013, Vol. 427/2013, pp. 43-62, DOI: 10.1007/978-3-642- 29694-9_3, Springer-Verlag Berlin Heidelberg. Published on arXiv at http://arxiv.org/abs/1403.2541.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Symbolic Neural Networks for Clustering Higher-Level Concepts</title>
		<author>
			<persName><forename type="first">K</forename><surname>Greer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSEAS/EUROPMENT International Conference on Computers and Computing (ICCC&apos;11)</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="378" to="386" />
		</imprint>
	</monogr>
	<note>Issue</note>
	<note type="raw_reference">Greer, K. (2011). Symbolic Neural Networks for Clustering Higher-Level Concepts, NAUN International Journal of Computers, Issue 3, Vol. 5, pp. 378 -386, extended version of the WSEAS/EUROPMENT International Conference on Computers and Computing (ICCC&apos;11).</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Some aspects of the theory of statistical control schemes</title>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Yashchin</surname></persName>
		</author>
		<idno type="DOI">10.1147/rd.312.0199</idno>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<title level="j" type="abbrev">IBM J. Res. &amp; Dev.</title>
		<idno type="ISSN">0018-8646</idno>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="199" to="205" />
			<date type="published" when="1987-03">1987</date>
			<publisher>IBM</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Yashchin, E., (1987), Some aspects of the theory of statistical control schemes, IBM J. Res. Develop., Vol. 31 No. 2, pp. 199 -205.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Acquiring Visibly Intelligent Behavior with Example-Guided Neuroevolution</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second National Conference on Artificial Intelligence (AAAI-07)</title>
				<meeting>the Twenty-Second National Conference on Artificial Intelligence (AAAI-07)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="801" to="808" />
		</imprint>
	</monogr>
	<note type="raw_reference">Bryant, B.D. and Miikkulainen, R., (2007), Acquiring Visibly Intelligent Behavior with Example- Guided Neuroevolution, In Proceedings of the Twenty-Second National Conference on Artificial Intelligence (AAAI-07), pp. 801 -808.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Benchmarks, Test Beds, Controlled Experimentation, and the Design of Agent Architectures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hanks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Pollack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="17" to="42" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hanks, S., Pollack, M.E., and Cohen, P.R., (1993), Benchmarks, Test Beds, Controlled Experimentation, and the Design of Agent Architectures, AI Magazine. Vol. 14, No. 4, pp. 17 -42.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tutorial on agent-based modelling and simulation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Macal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>North</surname></persName>
		</author>
		<idno type="DOI">10.1057/jos.2010.3</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Simulation</title>
		<title level="j" type="abbrev">Journal of Simulation</title>
		<idno type="ISSN">1747-7778</idno>
		<idno type="ISSNe">1747-7786</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="151" to="162" />
			<date type="published" when="2010-09">2010</date>
			<publisher>Informa UK Limited</publisher>
		</imprint>
	</monogr>
	<note>Journal of Simulation</note>
	<note type="raw_reference">Macal, C.M. and North, M.J., (2010), Tutorial on agent-based modelling and simulation, Journal of Simulation, Operational Research Society Ltd., Vol. 4, pp. 151-162.</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Recursive distributed representations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pollack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ringuette</surname></persName>
		</author>
		<idno type="DOI">10.1016/0004-3702(90)90005-k</idno>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<title level="j" type="abbrev">Artificial Intelligence</title>
		<idno type="ISSN">0004-3702</idno>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="77" to="105" />
			<date type="published" when="1990-11">1990</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Pollack, M., and Ringuette, M., (1990), Introducing the TILEWORLD: Experimentally Evaluating Agent Architectures, In Proceedings of the Eighth National Conference on Artificial Intelligence, Menlo Park, Calif.: American Association for Artificial Intelligence, pp. 183 - 189.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">On</forename><surname>Blakeslee</surname></persName>
		</author>
		<author>
			<persName><surname>Intelligence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Times Books</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hawkins, J. and Blakeslee, S. On Intelligence. Times Books, 2004.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Crossmodal binding through neural coherence: implications for multisensory processing</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Senkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Till</forename><forename type="middle">R</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">J</forename><surname>Foxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><forename type="middle">K</forename><surname>Engel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tins.2008.05.002</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Neurosciences</title>
		<title level="j" type="abbrev">Trends in Neurosciences</title>
		<idno type="ISSN">0166-2236</idno>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="401" to="409" />
			<date type="published" when="2008-08">2008</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Senkowski, D., Schneider, T.R., Foxe, J.J. and Engel, A.K., (2008), Crossmodal binding through neural coherence: implications for multisensory processing, Trends in Neurosciences, Vol. 31, No. 8, pp. 401 -409, DOI: 10.1016/j.tins.2008.05.002.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">CHARACTER RECOGNITION IN NATURAL IMAGES</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>De Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
		<idno type="DOI">10.5220/0001770102730280</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Computer Vision Theory and Applications</title>
				<meeting>the Fourth International Conference on Computer Vision Theory and Applications<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>SciTePress - Science and and Technology Publications</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">de Campos, T.E., Babu, B.R. and Varma, M., (2009), Character recognition in natural images, In Proceedings of the International Conference on Computer Vision Theory and Applications (VISAPP), Lisbon, Portugal.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">And-or Graphs, Theorem-proving Graphs and Bi-directional Search</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kowalski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kowalski, R., (1972), And-or Graphs, Theorem-proving Graphs and Bi-directional Search, Machine Intelligence 7.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An Unsupervised Pattern Clustering Approach for Identifying Abnormal User Behaviors in Smart Homes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sukanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Gayathri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCSN International Journal of Computer Science and Network</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="115" to="122" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sukanya, P. and Gayathri, K.S., (2013), An Unsupervised Pattern Clustering Approach for Identifying Abnormal User Behaviors in Smart Homes, IJCSN International Journal of Computer Science and Network, Vol. 2, Issue 3, pp. 115 -122.</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Visual Feature Integration and the Temporal Correlation Hypothesis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.ne.18.030195.003011</idno>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Neuroscience</title>
		<title level="j" type="abbrev">Annu. Rev. Neurosci.</title>
		<idno type="ISSN">0147-006X</idno>
		<idno type="ISSNe">1545-4126</idno>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="555" to="586" />
			<date type="published" when="1995-03">1995</date>
			<publisher>Annual Reviews</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Singer, W. and Gray, C.M. (1995). Visual feature integration and the temporal correlation hypothesis, Annu Rev Neurosci. Vol. 18, pp. 555 -586.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The neural binding problem(s)</title>
		<author>
			<persName><forename type="first">Jerome</forename><surname>Feldman</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11571-012-9219-8</idno>
	</analytic>
	<monogr>
		<title level="j">Cognitive Neurodynamics</title>
		<title level="j" type="abbrev">Cogn Neurodyn</title>
		<idno type="ISSN">1871-4080</idno>
		<idno type="ISSNe">1871-4099</idno>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2013">2013</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Feldman, J., (2013), The Neural Binding Problem(s), Cognitive neurodynamics, Vol. 7, No. 1, pp. 1-11.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Cognitive Binding Problem: From Kant to Quantum Neurodynamics</title>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">A</forename><surname>Mashour</surname></persName>
		</author>
		<idno type="DOI">10.14704/nq.2004.2.1.33</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroQuantology</title>
		<title level="j" type="abbrev">Neuroquantology</title>
		<idno type="ISSNe">1303-5150</idno>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="38" />
			<date type="published" when="2004">2004</date>
			<publisher>NeuroQuantology Journal</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Mashour, G.A., (2004), The Cognitive Binding Problem: From Kant to Quantum Neurodynamics, NeuroQuantology, Issue 1, pp. 29-38.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>O'reilly</surname></persName>
		</author>
		<title level="m">Neural Mechanisms of Binding in the Hippocampus and Neocortex: Insights from Computational Models</title>
				<editor>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Zimmer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Mecklinger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Lindenberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="193" to="220" />
		</imprint>
	</monogr>
	<note>Handbook of binding and memory: Perspectives from cognitive neuroscience</note>
	<note type="raw_reference">Cer, D.M. and O&apos;Reilly, R.C., (2006), Neural Mechanisms of Binding in the Hippocampus and Neocortex: Insights from Computational Models, H.D. Zimmer, A. Mecklinger, and U. Lindenberger (Eds) Handbook of binding and memory: Perspectives from cognitive neuroscience, pp.193 -220, Oxford University Press.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">(1986) D. E. Rumelhart, G. E. Hinton, and R. J. Williams, &quot;Learning internal representations by error propogation,&quot; [i]Parallel Distributed Processing: Explorations in the Microstructures of Cognition[/i], Vol. I, D. E. Rumelhart and J. L. McClelland (Eds.) Cambridge, MA: MIT Press, pp. 318-362.(1986) David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams, &quot;Learning representations by back-propogating errors,&quot; [i]Nature[/i] 323:533-536.</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<idno type="DOI">10.7551/mitpress/4943.003.0042</idno>
	</analytic>
	<monogr>
		<title level="m">Neurocomputing, Volume 1</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><surname>Pdp Research</surname></persName>
		</editor>
		<editor>
			<persName><surname>Group</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="673" to="700" />
		</imprint>
	</monogr>
	<note type="raw_reference">Hinton, G.E., McClelland, J.L., and Rumelhart, D.E., (1986), Distributed representations. In D.E. Rumelhart, J.L. McClelland, &amp; PDP Research Group (Eds.), Parallel distributed processing. Vol. 1: Foundations (Chap. 3, pp. 77-109). Cambridge, MA: MIT Press.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The biological principles of swarm intelligence</title>
		<author>
			<persName><forename type="first">Simon</forename><surname>Garnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacques</forename><surname>Gautrais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Theraulaz</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11721-007-0004-y</idno>
	</analytic>
	<monogr>
		<title level="j">Swarm Intelligence</title>
		<title level="j" type="abbrev">Swarm Intell</title>
		<idno type="ISSN">1935-3812</idno>
		<idno type="ISSNe">1935-3820</idno>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="31" />
			<date type="published" when="2007-07-17">2007</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Garnier, S., Gautrais, J., and Theraulaz, G., (2007), The biological principles of swarm intelligence, Swarm Intelligence. Vol. 1, pp. 3 -31.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural networks and physical systems with emergent collective computational abilities.</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.79.8.2554</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<title level="j" type="abbrev">Proc. Natl. Acad. Sci. U.S.A.</title>
		<idno type="ISSN">0027-8424</idno>
		<idno type="ISSNe">1091-6490</idno>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2554" to="2558" />
			<date type="published" when="1982-04">1982</date>
			<publisher>Proceedings of the National Academy of Sciences</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Hopfield, J.J. (1982). Neural networks and physical systems with emergent collective computational abilities, Proceedings of the National Academy of Sciences of the USA, vol. 79, No. 8, pp. 2554 -2558.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Neural Networks: A Systematic Introduction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rojas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
	<note>Berlin and online at books.google.com</note>
	<note type="raw_reference">Rojas, R. Neural Networks: A Systematic Introduction, Springer-Verlag, Berlin and online at books.google.com, 1996.</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Marin Karmitz is a phenomenon: one of the most prolic French producers of his generation. Alongside his production activities, he has also set up MK2, a successful distribution, exhibition, and sales company. Louis Malle, Alain Resnais, Claude Chabrol, Jean-Luc Godard—he has worked with them all. Karmitz has also branched further aeld, producing movies by Iranian master Abbas Kiarostami, by great Polish director Krzysztof Kieslowski, and by American auteur Gus Van Sant. Notable lms on the producer’s lmography include the Three Colors trilogy with Kieslowski (1993 to 1994), Chabrol’s version of Madame Bovary (1991), Resnais’ Mélo (1986), Kiarostami’s The Wind Will Carry Us (1999), and Jonathan Nossiter’s Signs &amp; Wonders (2000). He also co-produced Van Sant’s Paranoid Park (2007). He was associate producer on Godard’s Every Man for Himself (1980), and his company produced Malle’s classic, Au Revoir Les Enfants (1987). There are several paradoxes about Karmitz. He is a gure of the 1960s, a radical leftist who fell foul of the lmmaking establishment in the turbulent post-1968 years. His directorial career was stopped in its tracks in the early 1970s and he was blacklisted. At the same time, this idealistic lmmaker with close links to the revolutionary movement proved to be an astute cinema owner and businessman. To outsiders, his lmmaking model seems akin to that of the Hollywood studios. His company is vertically integrated, handling everything from production to exhibition. He suggests his business is more in the tradition of the Lumière brothers. There is, of course, one very big difference between Karmitz and the Hollywood majors. Karmitz only produces lms by auteurs. Karmitz is nothing if not international in outlook. He came to France as a refugee. Born in 1938, Karmitz spent his early years in Romania. Once established as a producer, he has worked with lmmakers all over the world, but that leads to another surprising fact about him. He doesn’t much like to travel. His passport, he says, is the cinema.</title>
		<idno type="DOI">10.4324/9780240823881-25</idno>
	</analytic>
	<monogr>
		<title level="m">FilmCraft: Producing</title>
				<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2013-07-04" />
			<biblScope unit="page" from="73" to="74" />
		</imprint>
	</monogr>
	<note>an MSc in Computer Science, and a DPhil in Artificial Intelligence in 1998. for example. He is also an experienced software engineer and has self-published one book</note>
	<note type="raw_reference">Kieran Greer completed a BSc in Geology, an MSc in Computer Science, and a DPhil in Artificial Intelligence in 1998. He currently runs his own company, Distributed Computing Systems (.co.uk), and specialises in the areas of Artificial Intelligence and Distributed Information Systems. His software products include &apos;licas&apos; and &apos;Textflo&apos;. He has worked previously at the two Universities in Northern Ireland and since then, as a freelancer. He maintains a research profile in his areas of expertise, where he has developed his own cognitive and neural network models, for example. He is also an experienced software engineer and has self-published one book.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
