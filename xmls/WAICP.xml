<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">What has AI in Common with Philosophy?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="1996-02-29">February 29, 1996</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">John</forename><surname>Mccarthy</surname></persName>
							<email>jmc@cs.stanford.edu</email>
							<affiliation key="aff0">
								<note type="raw_affiliation">Computer Science Department Stanford University Stanford, CA 94305, U.S.A.</note>
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">What has AI in Common with Philosophy?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="1996-02-29">February 29, 1996</date>
						</imprint>
					</monogr>
					<idno type="MD5">DFF23EEDC3207CFCEE594582D319E289</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3-SNAPSHOT" ident="GROBID" when="2023-02-13T23:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p><s>AI needs many ideas that have hitherto been studied only by philosophers.</s><s>This is because a robot, if it is to have human level intelligence and ability to learn from its experience, needs a general world view in which to organize facts.</s><s>It turns out that many philosophical problems take new forms when thought about in terms of how to design a robot.</s><s>Some approaches to philosophy are helpful and others are not.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p><s>Artificial intelligence and philosophy have more in common than a science usually has with the philosophy of that science.</s><s>This is because human level artificial intelligence requires equipping a computer program with some philosophical attitudes, especially epistemological.</s></p><p><s>The program must have built into it a concept of what knowledge is and how it is obtained.</s></p><p><s>If the program is to reason about what it can and cannot do, its designers will need an attitude to free will.</s><s>If it is to do meta-level reasoning about what it can do, it needs an attitude of its own to free will.</s></p><p><s>If the program is to be protected from performing unethical actions, its designers will have to build in an attitude about that.</s></p><p><s>Unfortunately, in none of these areas is there any philosophical attitude or system sufficiently well defined to provide the basis of a usable computer program.</s></p><p><s>Most AI work today does not require any philosophy, because the system being developed doesn't have to operate independently in the world and have a view of the world.</s><s>The designer of the program does the philosophy in advance and builds a restricted representation into the program.</s></p><p><s>Building a chess program requires no philosophy, and Mycin recommended treatments for bacterial infections without even having a notion of processes taking place in time.</s><s>However, the performance of Mycin-like programs and chess programs is limited by their lack of common sense and philosophy, and many applications will require a lot.</s><s>For example, robots that do what they think their owners want will have to reason about wants.</s></p><p><s>Not all philosophical positions are compatible with what has to be built into intelligent programs.</s><s>Here are some of the philosophical attitudes that seem to me to be required.</s></p><p><s>1. Science and common sense knowledge of the world must both be accepted.</s></p><p><s>There are atoms, and there are chairs.</s><s>We can learn features of the world at the intermediate size level on which humans operate without having to understand fundamental physics.</s><s>Causal relations must also be used for a robot to reason about the consequences of its possible actions.</s></p><p><s>2. Mind has to be understood a feature at a time.</s><s>There are systems with only a few beliefs and no belief that they have beliefs.</s><s>Other systems will do extensive introspection.</s><s>Contrast this with the attitude that unless a system has a whole raft of features it isn't a mind and therefore it can't have beliefs.</s></p><p><s>3. Beliefs and intentions are objects that can be formally described.</s></p><p><s>4. A sufficient reason to ascribe a mental quality is that it accounts for behavior to a sufficient degree.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">It is legitimate to use approximate concepts not capable of iff definition.</head><p><s>For this it is necessary to relax some of the criteria for a concept to be meaningful.</s><s>It is still possible to use mathematical logic to express approximate concepts.</s></p><p><s>6.</s><s>Because a theory of approximate concepts and approximate theories is not available, philosophical attempts to be precise have often led to useless hair splitting.</s></p><p><s>7. Free will and determinism are compatible.</s><s>The deterministic process that determines what an agent will do involves its evaluation of the consequences of the available choices.</s><s>These choices are present in its consciousness and can give rise to sentences about them as they are observed.</s></p><p><s>8. Self-consciousness consists in putting sentences about consciousness in memory.</s></p><p><s>9. Twentieth century philosophers became to critical of reification.</s><s>Many of the criticism don't apply when the entities reified are treated as approximate concepts.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Philosophy of Artificial Intelligence</head><p><s>One can expect there to be an academic subject called the philosophy of artificial intelligence analogous to the existing fields of philosophy of physics and philosophy of biology.</s><s>By analogy it will be a philosophical study of the research methods of AI and will propose to clarify philosophical problems raised.</s><s>I suppose it will take up the methodological issues raised by Hubert Dreyfus and John Searle, even the idea that intelligence requires that the system be made of meat.</s></p><p><s>Presumably some philosophers of AI will do battle with the idea that AI is impossible (Dreyfus), that it is immoral (Weizenbaum) and that the very concept is incoherent (Searle).</s></p><p><s>It is unlikely to have any more effect on the practice of AI research than philosophy of science generally has on the practice of science.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Epistemological Adequacy</head><p><s>Formalisms for representing facts about the world have to be adequate for representing the information actually available.</s><s>A formalism that represented the state of the world by the positions and velocities of molecules is inadequate if the system can't observe positions and velocities, although such a formalism may be the best for deriving thermodynamic laws.</s></p><p><s>The common sense world needs a language to describe objects, their relations and their changes quite different from that used in physics and engineering.</s><s>The key difference is that the information is less complete.</s><s>It needs to express what is actually known that can permit a robot to determine the expected consequences of the actions it contemplates.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Free Will</head><p><s>An attitude toward the free will problem needs to be built into robots in which the robot can regard itself as having choices to make, i.e. as having free will.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Natural Kinds</head><p><s>Natural kinds are described rather than defined.</s><s>We have learned about lemons and experienced them as small, yellow fruit.</s><s>However, this knowledge does not permit an iff definition.</s><s>Lemons differ from other fruit in ways we don't yet know about.</s><s>There is no continuous gradation from lemons to oranges.</s><s>On the other hand, geneticists could manage to breed large blue lemons by tinkering with the genes, and there might be good reasons to call the resulting fruit lemons.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Four Stances</head><p><s>Daniel Dennett named three stances one can take towards an object or system.</s><s>The first is the physical stance in which the physical structure of the system is treated.</s><s>The second is the intentional stance in which the system is understood in terms of its beliefs, goals and intentions.</s><s>The third is the design stance in which the system is understood in terms of its composition out of parts.</s><s>One more stance we'll call the functional stance.</s><s>We take the functional stance toward an object when we ask what it does without regard to its physics or composition.</s><s>The example I like to give is a motel alarm clock.</s><s>The user may not notice whether it is mechanical, an electric motor timed by the power line or electronic timed by a quartz crystal.<ref type="foot" target="#foot_0">1</ref></s><s>Each stance is appropriate in certain conditions.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Ontology and Reification</head><p><s>Quine wrote that one's ontology coincides with the ranges of the variables in one's formalism.</s><s>This usage is entirely appropriate for AI.</s><s>Present philosophers, Quine perhaps included, are often too stingy in the reifications they permit.</s><s>It is sometimes necessary to quantify over beliefs, hopes and goals.</s></p><p><s>When programs interact with people or other programs they often perform speech acts in the sense studied by Austin and Searle.</s><s>Quantification over promises, obligations, questions, answers to questions, offers, acceptances and declinations are required.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Counterfactuals</head><p><s>An intelligent program will have to use counterfactual conditional sentences, but AI needs to concentrate on useful counterfactuals.</s><s>An example is "If another car had come over the hill when you passed just now, there would have been a headon collision."</s><s>Believing this counterfactual might change one's driving habits, whereas the corresponding material conditional, obviously true in view of the false antecedent, could have no such effect.</s><s>Counterfactuals permit systems to learn from experiences they don't actually have.</s></p><p><s>Unfortunately, the Stalnaker-Lewis closest possible world model of counterfactuals doesn't seem helpful in building programs that can formulate and use them.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Philosophical Pitfalls</head><p><s>There is one philosophical view that is attractive to people doing AI but which limits what can be accomplished.</s><s>This is logical positivism which tempts AI people to make systems that describe the world in terms of relations between the program's motor actions and its subsequent observations.</s><s>Particular situations are sometimes simple enough to admit such relations, but a system that only uses them will not even be able to represent facts about simple physical objects.</s><s>It cannot have the capability of a two week old baby.</s></p><p><s>10 Philosophers!</s><s>Help!</s><s>Previous philosophical discussion of certain conecpts has been helpful to AI.</s><s>In this I include the Austin-Searle discussion of speech acts, Grice's discussion of conversational implicatures, various discussions of natural kinds, modal logic and the notion of philosophy as a science.</s><s>Maybe some of the philosophical discussions of causality and counterfactuals will be useful for AI.</s><s>In this paragraph I have chosen to be stingy with credit.</s></p><p><s>Philosophers could help artificial intelligence more than they have done if they would put some attention to some more detailed conceptual problems such as the following:</s></p><p><s>belief What belief statements are useful?</s></p><p><s>how What is the relation between naming an occurrence and its suboccurrences?</s><s>He went to Boston.</s><s>How?</s><s>He drove to the airport, parked and took UA 34.</s></p><p><s>responsiveness When is the answer to a question responsive?</s><s>Thus "Vladimir's wife's husband's telephone number" is a true but not responsive answer to a request for Vladimir's telephone number.</s></p><p><s>useful causality What causal statements are useful?</s></p><p><s>useful counterfactuals What counterfactuals are useful and why? "If another car had come over the hill when you passed, there would have been a head-on collision."</s></p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">I had called this the design stance, and I thank Aaron Sloman for pointing out my mistake and suggesting functional stance.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">ROIG represent actual writing practices, then the issue of how paraphrasing is defined within and across disciplines needs to be seriously considered. Most modern manuals of writing that discuss the parameters of correct para-phrasing (e.g., Aaron, 1998; Hacker, 1994; Nadell et al., 1994; Troyka, 1999) are relatively clear on the extent to which the original material must be modified to be considered properly paraphrased. For example, Troyka stated, &quot;Even though a paraphrase is not a direct quotation, you must use DOCUMENTATION to credit your source. Also, you must reword your source material, not merely change a few words&quot; (p. 498). In another manual, Aaron suggested that when paraphrasing a source, &quot;Restate the source&apos;s ideas in your own words and sentence structures&quot; (p. 257). Other writers offer even stricter definitions of paraphrasing. For example, consider Howard&apos;s (1993; cited in Howard, 1999) definition of patchwriting, a form of writing that she considers plagiarism: &quot;copying from a source text and then deleting some words, altering grammatical structure, or plugging in one-for-one synonym-substitutes&quot; (p. 89). Accordingly, paraphrases such as those supplied by respondents who appropriated strings of words in Studies 2 and 3 are certainly not within the guidelines of paraphrasing outlined by these manuals and would there-fore constitute possible instances of plagiarism. If indeed college professors paraphrase in a manner similar to that observed in the studies in this article, can we conclude that a small but significant proportion of writing by college professors may be classified as plagiarism? Obviously, such a conclusion would depend on a number of factors. For example, has text appropria-tion occurred systematically across various works cited throughout the paper, or is it confined to one or two instances of, say, a description of a complex methodology section of an experimental research report? In addition, how many strings of con-secutive words have been appropriated and of what length are these strings of text? Clearly, these and other issues need to be taken into account when making a deter-mination of plagiarism. One important factor to be considered when reviewing others&apos; work for potential plagiarism is the discipline of the writer. For example, if the writer is a psychology student or professor, then perhaps those paraphrases might be acceptable within the psychology community. Consider how the psychology profession defines para-phrasing and plagiarism. The Publication Manual of the American Psychological Association (APA; APA, 1994), a source used by most psychologists and others in the social sciences (e.g., sociologists, social workers), offers the following guide-lines: &quot;Summarizing a passage or rearranging the order of a sentence and changing some of the words is paraphrasing&quot; (p. 292). A comparison of the Publication Man-ual definition with the definitions of traditional writing manuals outlined earlier in-dicates some obvious differences in the extent to which text should be modified to be considered a proper paraphrase. Unfortunately, the absence of a general operational definition for paraphrasing leaves plenty of room for disagreement as to when a para-phrase might be considered an instance of plagiarism.</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">V O</forename><surname>Daniel Dennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hilary</forename><surname>Quine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Putnam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Grice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Searle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Stalnaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><surname>Sloman</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781410608277-18</idno>
		<ptr target="http://www-formal.stanford.edu/jmc/.I" />
	</analytic>
	<monogr>
		<title level="m">Academic Dishonesty</title>
				<imprint>
			<publisher>Psychology Press</publisher>
			<date type="published" when="2003-07-30" />
			<biblScope unit="page" from="105" to="105" />
		</imprint>
	</monogr>
	<note>would also refer to work by the following philosophers: Rudolf Carnap. Richard von Mises. Much of the bibliography in Aaron Sloman&apos;s previous article is applicable to this one. Acknowledgement: Work partly supported by ARPA (ONR) grant N00014-94-1-0775</note>
	<note type="raw_reference">proper bibliography. Such a bibliography would refer to a number of papers, some of mine being reprinted in my Formalizing Common Sense Many are available via my Web page http://www-formal.stanford.edu/jmc/. I would also refer to work by the following philosophers: Rudolf Carnap, Daniel Dennett, W. V. O. Quine, Hilary Putnam, Paul Grice, John Searle, Robert Stalnaker, David Lewis, Aaron Sloman, Richard von Mises. Much of the bibliography in Aaron Sloman&apos;s previous article is applicable to this one. Acknowledgement: Work partly supported by ARPA (ONR) grant N00014- 94-1-0775.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
